# TaxBridge V5 - Phase B Security & Hardening Baseline

**Status:** ‚úÖ COMPLETE  
**Date:** January 15, 2026  
**Version:** 5.0.2

---

## 1. Security Protections Inventory

### ‚úÖ Implemented Security Middleware

| Protection | Implementation | Status | Notes |
|------------|----------------|--------|-------|
| **Helmet (CSP)** | `@fastify/helmet` | ‚úÖ ACTIVE | CSP with strict directives |
| **CORS** | `@fastify/cors` | ‚úÖ ACTIVE | Origin whitelist from `ALLOWED_ORIGINS` |
| **Rate Limiting** | `backend/src/lib/security.ts` | ‚úÖ ACTIVE | Redis-backed, multi-tier limits |
| **Request Compression** | `@fastify/compress` | ‚úÖ ACTIVE | gzip/deflate, >1KB threshold |
| **Trust Proxy** | Fastify config | ‚úÖ ACTIVE | IP extraction for rate limiting |
| **Security Headers** | Custom `onRequest` hook | ‚úÖ ACTIVE | X-Frame, XSS, HSTS, CSP |
| **Request Tracing** | `lib/request-tracer.ts` | ‚úÖ ACTIVE | X-Request-ID, X-Correlation-ID |
| **Error Sanitization** | Error handler | ‚úÖ ACTIVE | 5xx = generic message |
| **Input Validation** | Zod schemas | ‚úÖ ACTIVE | All routes type-safe |

### üîí Rate Limiting Configuration

**Current Limits (from `backend/src/lib/security.ts`):**

```typescript
RATE_LIMITS = {
  api: { window: 60s, max: 100, blockDuration: 300s },      // API endpoints
  ussd: { window: 60s, max: 10, blockDuration: 300s },      // USSD sessions
  sms: { window: 300s, max: 5, blockDuration: 900s },       // SMS sending
  auth: { window: 900s, max: 5, blockDuration: 1800s },     // Failed login
  webhook: { window: 60s, max: 50, blockDuration: 300s }    // Remita/DigiTax
}
```

**Implementation Details:**
- Redis-backed sliding window
- IP-based tracking (extracted from `X-Forwarded-For` or socket)
- Auto-blocking on threshold breach
- Health endpoints (`/health`, `/ready`, `/metrics`) exempt from rate limits

**‚ö†Ô∏è Recommendations:**
- [ ] Add configurable environment variables for rate limit thresholds
- [ ] Implement graduated penalties (soft warnings before hard blocks)
- [ ] Add admin API to view/clear rate limit blocks

---

## 2. Secrets Management Audit

### üîë Required Secrets (from `.env.production.example`)

| Secret | Usage | Storage | Rotation |
|--------|-------|---------|----------|
| `DATABASE_URL` | Postgres connection | Render/Supabase vault | Manual |
| `REDIS_URL` | Redis connection | Render vault | Manual |
| `JWT_SECRET` | Access token signing | ‚ö†Ô∏è `.env` file | ‚ùå NONE |
| `JWT_REFRESH_SECRET` | Refresh token signing | ‚ö†Ô∏è `.env` file | ‚ùå NONE |
| `ENCRYPTION_KEY` | AES-256-GCM (TIN/NIN) | ‚ö†Ô∏è `.env` file | ‚ùå NONE |
| `SESSION_SECRET` | Session cookies | ‚ö†Ô∏è `.env` file | ‚ùå NONE |
| `WEBHOOK_SECRET` | Webhook HMAC validation | ‚ö†Ô∏è `.env` file | ‚ùå NONE |
| `DIGITAX_API_KEY` | DigiTax authentication | ‚ö†Ô∏è `.env` file | Manual |
| `DIGITAX_HMAC_SECRET` | DigiTax request signing | ‚ö†Ô∏è `.env` file | Manual |
| `REMITA_API_KEY` | Remita authentication | ‚ö†Ô∏è `.env` file | Manual |
| `REMITA_WEBHOOK_SECRET` | Remita webhook validation | ‚ö†Ô∏è `.env` file | Manual |
| `AT_API_KEY` | Africa's Talking SMS | ‚ö†Ô∏è `.env` file | Manual |
| `SENTRY_DSN` | Error tracking | ‚ö†Ô∏è `.env` file | N/A |

### ‚ùå Critical Gaps Identified

1. **No Automated Secret Rotation**
   - JWT secrets, encryption keys, and webhook secrets are static
   - No rotation scripts or vault integration exists
   - Risk: Compromised secrets require manual code/config changes

2. **Secret Schema Drift Risk**
  - `JWT_REFRESH_SECRET` and `ENCRYPTION_KEY` are now explicitly validated in `backend/src/server.ts`
  - **Risk:** Future edits could reintroduce drift between auth/encryption code and env validation

3. **Hardcoded Secrets in Tooling**
  - Status: Fixed (removed hardcoded DigiTax key from `backend/src/tools/digitax-test.ts`)

### ‚úÖ Immediate Actions Required

- [x] **Add missing secrets to `envSchema` in `backend/src/server.ts`:**
  - `JWT_REFRESH_SECRET`, `ENCRYPTION_KEY`, `SESSION_SECRET`, `WEBHOOK_SECRET`, plus optional `*_PREVIOUS` entries now enforced through Fastify env schema (see [backend/src/server.ts](backend/src/server.ts)).

- [x] **Create secret rotation scripts:**
  - `infra/scripts/rotate-jwt-secrets.sh` automates dual-key JWT rotation (updates `*_PREVIOUS` and active keys).
  - `infra/scripts/rotate-webhook-secrets.sh` rotates DigiTax/Remita/webhook HMAC secrets.
  - Encryption key rotation remains pending pending data re-encryption tooling (`rotate-encryption-key.sh` still TODO).

- [ ] **Implement vault integration:**
  - Option 1: Render environment variables (manual rotation)
  - Option 2: HashiCorp Vault (automated rotation)
  - Option 3: AWS Secrets Manager / Azure Key Vault

- [x] **Document rotation procedures:**
  - JWT auth now supports dual validation via `JWT_SECRET_PREVIOUS`/`JWT_REFRESH_SECRET_PREVIOUS` (see [backend/src/services/auth.ts](backend/src/services/auth.ts)).
  - Scripts print step-by-step operator guidance; baseline updated to reference cadence.
  - Webhook rotation instructions captured in `infra/scripts/rotate-webhook-secrets.sh` output banner.

---

## 3. Encryption Implementation Review

### üîê Current Implementation (`backend/src/services/encryption.ts`)

**Algorithm:** AES-256-GCM (authenticated encryption)

**Encrypted Fields (Prisma middleware):**
- `tin` (Tax Identification Number)
- `nin` (National Identification Number)
- `duploClientId` / `duploClientSecret`
- `remitaMerchantId` / `remitaApiKey`
- `ecdsaPrivateKey`

**Key Derivation:**
```typescript
const secret = process.env.ENCRYPTION_KEY || crypto.randomBytes(32).toString('hex');
this.key = crypto.scryptSync(secret, 'taxbridge-salt', 32);
```

**Format:** `iv:authTag:ciphertext` (hex-encoded)

### ‚úÖ Strengths
- Authenticated encryption prevents tampering
- Prisma middleware automatically encrypts/decrypts on read/write
- Constant-time salt (`'taxbridge-salt'`) ensures deterministic key derivation

### ‚ö†Ô∏è Weaknesses & Recommendations

1. **Ephemeral Key Fallback**
   - **Issue:** If `ENCRYPTION_KEY` not set, generates random key ‚Üí data unrecoverable on restart
   - **Fix:** Make `ENCRYPTION_KEY` required in env schema (throw error if missing)

2. **Static Salt**
   - **Issue:** Using hardcoded salt `'taxbridge-salt'` reduces security margin
   - **Recommendation:** Use per-record salt (stored alongside IV) for defense-in-depth

3. **No Key Versioning**
   - **Issue:** Cannot rotate encryption keys without manual re-encryption
   - **Recommendation:** Add `encryptionKeyVersion` field to User model; support multi-key decryption

4. **Missing Audit Trail**
   - **Issue:** No logging of encryption/decryption operations
   - **Recommendation:** Log access to sensitive fields (with redaction) in `AuditLog` table

### üéØ Action Items

- [ ] **Make `ENCRYPTION_KEY` required** in `backend/src/server.ts` env schema
- [ ] **Add key versioning support:**
  - Store `encryptionKeyVersion: Int` in User model
  - Decrypt with version-specific key from `ENCRYPTION_KEY_V1`, `ENCRYPTION_KEY_V2`, etc.
  - Background job to re-encrypt old records with new key version

- [ ] **Implement audit logging for sensitive field access:**
  ```typescript
  action: 'sensitive_field_read',
  metadata: { field: 'tin', userId: '...' }
  ```

- [ ] **Document encryption key rotation procedure:**
  - Generate new key (`ENCRYPTION_KEY_V2`)
  - Deploy with dual-key support
  - Run migration script to re-encrypt all records
  - Remove old key after verification

---

## 4. Connection Pooling Analysis

### üîå PostgreSQL (Prisma)

**Current Configuration:**
- **No explicit pool configuration** in `prisma/schema.prisma`
- **Default Prisma pool settings:**
  - Min connections: 2
  - Max connections: 10 (for serverless; unlimited for long-running)
  - Idle timeout: 10s
  - Connection timeout: 5s

**Prisma Client Instantiation:**
- `backend/src/server.ts` line 42: `const prisma = new PrismaClient();`
- **Issue:** Multiple files create separate `PrismaClient` instances:
  - `server.ts`, `growth.ts`, `privacy.ts`, `monitoring.ts`, `errorRecovery.ts`, `deadlineReminder.ts`, `tools/*`
  - Each instance creates its own connection pool ‚Üí pool exhaustion risk

### ‚ö†Ô∏è Connection Pool Issues

1. **Multiple PrismaClient Instances**
   - **Impact:** 10 files √ó 10 connections = 100 potential connections (exceeds most free-tier limits)
   - **Fix:** Singleton pattern with shared `PrismaClient` instance

2. **No Production Pool Tuning**
   - **Issue:** Using default settings not optimized for production load
   - **Recommendation:** Configure via `DATABASE_URL` connection string:
     ```
     postgresql://user:pass@host:5432/db?connection_limit=20&pool_timeout=20
     ```

### üîß Redis (ioredis + BullMQ)

**Current Configuration (`backend/src/queue/client.ts`):**
```typescript
new Redis(process.env.REDIS_URL, {
  maxRetriesPerRequest: null  // Required for BullMQ
});
```

**Issues:**
- **No connection pooling configured** (ioredis creates single connection by default)
- **No reconnection strategy** beyond default exponential backoff
- **No max connections limit** for multiple queue instances

**BullMQ Workers:**
- `invoiceSyncWorker` (queue/index.ts)
- Email queue (services/notifications.ts)
- SMS queue (integrations/comms/)
- Payment webhook queue (routes/payments.ts)

Each worker creates a separate Redis connection ‚Üí potential for connection leaks.

### üéØ Connection Pooling Recommendations

**Postgres:**
- [x] **Create singleton PrismaClient:** implemented in [backend/src/lib/prisma.ts](backend/src/lib/prisma.ts) and rolled out across all services/tools.

- [x] **Configure pool via DATABASE_URL:** query parameters (`connection_limit`, `pool_timeout`) now injected automatically when instantiating Prisma, with overrides exposed via `DATABASE_POOL_MAX` / `DATABASE_POOL_TIMEOUT_MS`.

- [x] **Add graceful shutdown:** `disconnectPrisma()` is invoked from server + worker shutdown handlers ensuring pools close cleanly.

**Redis:**
- [x] **Configure connection pool:** `backend/src/queue/client.ts` now centralizes Redis creation with retry strategy, lazy connect, and schedulers per queue.

- [x] **Share Redis connection** across BullMQ queues (already done in `client.ts`).

- [x] **Add connection monitoring:** `queue/client.ts` listens for `error`/`connect` events and logs health.

### ‚úÖ BullMQ Policy Upgrades
- Invoice and payment queues now ship with opinionated defaults (attempts, exponential/fixed backoff, rate limiter, timeouts) configured in [backend/src/queue/client.ts](backend/src/queue/client.ts).
- `invoiceSyncWorker` runs with configurable concurrency plus a circuit breaker that pauses the worker when consecutive failures exceed the defined threshold, resuming automatically after cooldown.
- Queue schedulers are registered to guarantee delayed jobs and retries fire even across deployments.

---

## 5. Load Test Configuration Review

**Current Setup:** `backend/load-test/k6-script.js`

### üìä Test Stages (27 minutes total)

```javascript
stages: [
  { duration: '2m', target: 10 },   // Ramp-up
  { duration: '5m', target: 10 },   // Baseline
  { duration: '2m', target: 50 },   // Medium load
  { duration: '5m', target: 50 },   // Sustain medium
  { duration: '2m', target: 100 },  // High load
  { duration: '5m', target: 100 },  // Sustain high
  { duration: '2m', target: 150 },  // Peak (NRS compliance)
  { duration: '3m', target: 150 },  // Sustain peak
  { duration: '2m', target: 0 }     // Ramp-down
]
```

### üéØ Performance Thresholds

| Metric | Threshold | Compliance |
|--------|-----------|------------|
| `http_req_duration` P95 | < 300ms | NRS requirement |
| `http_req_failed` | < 10% | Error tolerance |
| `duplo-submit` P95 | < 2000ms | DigiTax SLA |
| `remita-rrr` P95 | < 3000ms | Remita SLA |
| `duplo-status` P95 | < 1000ms | Status check |

### ‚úÖ Well-Configured Elements

- Comprehensive scenarios (health, invoice, payment, e-invoice)
- UBL XML generation with compliant structure
- Custom metrics for integration-specific errors
- Realistic test data generation

### ‚ö†Ô∏è Gaps & Recommendations

1. **Missing Scenarios:**
   - [ ] USSD session simulation (`/ussd` endpoints)
   - [ ] SMS webhook handling (`/sms/callback`)
   - [ ] Admin dashboard API (`/admin/*`)
   - [ ] Offline sync burst (100s of invoices from single user)

2. **No Database State Cleanup:**
   - [ ] Add setup/teardown scripts to reset test data between runs
   - [ ] Pre-populate database with test users/invoices for consistent baselines

3. **Missing Real Integration Tests:**
   - Current script generates data but doesn't verify:
     - [ ] DigiTax CSID/IRN returned correctly
     - [ ] Remita RRR format validation
     - [ ] QR code generation

4. **No Soak Testing:**
   - [ ] Add 1-hour sustained load test (50 VU) to detect memory leaks
   - [ ] Monitor Postgres/Redis connection count over time

### üéØ Action Items

- [ ] **Create test suites:**
  - `k6-smoke.js` (5 min, 10 VU) - Quick validation
  - `k6-load.js` (27 min, 150 VU peak) - Current script
  - `k6-soak.js` (1 hour, 50 VU) - Memory leak detection
  - `k6-spike.js` (Instant 200 VU ‚Üí 0) - Circuit breaker validation

- [ ] **Add database fixtures:**
  - `load-test/fixtures/setup.sql` - Seed test users/invoices
  - `load-test/fixtures/teardown.sql` - Clean up after tests

- [ ] **Integrate with CI:**
  - Run smoke test on every PR
  - Run full load test before production deploy
  - Fail deployment if P95 latency > 300ms

---

## 6. BullMQ Retry Policies

**Current Configuration:** `backend/src/queue/index.ts`

### üìã Invoice Sync Worker

**No explicit retry configuration** - using BullMQ defaults:
- Max attempts: 3
- Backoff: Exponential (1s, 2s, 4s)
- No custom retry logic

**Worker Implementation:**
```typescript
invoiceSyncWorker = new Worker('invoice-sync', async (job) => {
  // ... DigiTax submission ...
}, { connection: getRedisConnection() });
```

### ‚ö†Ô∏è Issues Identified

1. **Generic Retry for All Errors**
   - DigiTax network errors (retriable) vs. validation errors (non-retriable) treated the same
   - Risk: Wasting retries on permanently failed jobs

2. **No Circuit Breaker**
   - If DigiTax is down, all jobs will retry 3√ó and fail ‚Üí queue backlog
   - No automatic pause/resume based on upstream health

3. **Silent Failures**
   - Failed jobs after max attempts are not explicitly handled
   - No alert/notification system for DLQ (dead letter queue)

### üéØ Recommended Retry Policy

```typescript
invoiceSyncWorker = new Worker('invoice-sync', async (job) => {
  // ... processing logic ...
}, {
  connection: getRedisConnection(),
  settings: {
    backoff: {
      type: 'exponential',
      delay: 5000  // Start at 5s
    },
    attempts: 5
  }
});

// Custom retry logic
invoiceSyncWorker.on('failed', async (job, err) => {
  if (err instanceof DigiTaxError) {
    if (err.code === 'VALIDATION_ERROR') {
      // Don't retry - validation errors are permanent
      await job.discard();
      await notifyAdmin('Invoice validation failed', { jobId: job.id, error: err });
    } else if (err.code === 'NETWORK_ERROR') {
      // Retry with longer backoff
      if (job.attemptsMade < 5) {
        await job.retry({ delay: job.attemptsMade * 10000 });
      }
    }
  }
});
```

### üéØ Action Items

- [x] **Implement job-specific retry policies:**
  - ‚úÖ Smart retry logic in [backend/src/queue/index.ts](backend/src/queue/index.ts)
  - ‚úÖ Circuit breaker pattern for DigiTax failures
  - ‚úÖ Exponential backoff with configurable parameters
  - ‚úÖ Job deduplication by invoiceId
  - ‚úÖ Graceful worker shutdown

- [x] **Implement DLQ monitoring:**
  - ‚úÖ Created [backend/src/services/dlq-monitor.ts](backend/src/services/dlq-monitor.ts)
  - ‚úÖ Periodic checks every 5 minutes (configurable via `DLQ_CHECK_INTERVAL_MS`)
  - ‚úÖ Configurable thresholds per queue:
    - `invoice-sync`: 10 failed jobs
    - `payment-webhook`: 5 failed jobs
    - `email-queue`: 20 failed jobs
    - `sms-queue`: 15 failed jobs
  - ‚úÖ Alerts via Sentry when thresholds exceeded
  - ‚úÖ Optional webhook notifications (`DLQ_ALERT_WEBHOOK_URL`)
  - ‚úÖ Admin operations:
    - Manual retry of failed jobs
    - Cleanup of old failed jobs (30-day retention)
  - ‚úÖ Metrics exposed via `/metrics` endpoint
  - ‚úÖ Graceful shutdown integration

- [x] **Add graduated penalties for retriable errors:**
  - ‚úÖ Exponential backoff implemented (5s base, configurable)
  - ‚úÖ Fixed backoff for non-retriable errors
  - ‚úÖ Rate limiting per queue (8 jobs/sec for invoice-sync)
  - ‚úÖ Circuit breaker pauses worker when failure threshold exceeded

- [x] **Configure rate limits:**
  - ‚úÖ All rate limits now configurable via environment variables:
    ```bash
    RATE_LIMIT_API_WINDOW=60
    RATE_LIMIT_API_MAX=100
    RATE_LIMIT_API_BLOCK=300
    RATE_LIMIT_USSD_WINDOW=60
    RATE_LIMIT_USSD_MAX=10
    # ... (see backend/.env.example)
    ```
  - ‚úÖ Updated [backend/src/lib/security.ts](backend/src/lib/security.ts)
  - ‚úÖ Documented in [backend/.env.example](backend/.env.example)

- [ ] **Implement DLQ cleanup cron:**
  - Schedule daily cleanup job via BullMQ scheduler
  - Retention policy: 30 days for failed jobs, 7 days for completed jobs

- [ ] **Add admin API for DLQ management:**
  - `GET /admin/queues/:name/dlq` - View failed jobs
  - `POST /admin/queues/:name/dlq/retry` - Retry failed jobs
  - `DELETE /admin/queues/:name/dlq/clean` - Clean old jobs
  - Invoice sync: 5 attempts, exponential backoff (5s ‚Üí 80s)
  - Email sending: 3 attempts, fixed backoff (10s)
  - SMS sending: 2 attempts, fixed backoff (30s)
  - Payment webhooks: 10 attempts, exponential backoff (critical)

- [ ] **Add circuit breaker:**
  ```typescript
  if (await checkDigiTaxHealth() === 'down') {
    await invoiceSyncQueue.pause();
    scheduleRetry(60000);  // Check again in 1 min
  }
  ```

- [ ] **Configure Dead Letter Queue:**
  ```typescript
  await failedJob.moveToFailed({ 
    message: err.message,
    dlq: true  // Move to DLQ after max attempts
  });
  ```

- [ ] **Add monitoring:**
  - Track retry counts per job type
  - Alert if DLQ size > 10 jobs
  - Dashboard showing queue health (active/waiting/failed)

---

## 7. Summary & Next Steps

### ‚úÖ Security Strengths

- Comprehensive middleware stack (Helmet, CORS, rate limiting)
- Multi-tier rate limiting with Redis backing
- AES-256-GCM encryption for sensitive fields
- Input validation with Zod
- Request tracing and error sanitization

### ‚ùå Critical Gaps Requiring Immediate Action

| Priority | Gap | Status | Action |
|----------|-----|--------|--------|
| **P0** | Missing JWT_REFRESH_SECRET in env schema | ‚úÖ FIXED | Added to `server.ts` |
| **P0** | Missing ENCRYPTION_KEY in env schema | ‚úÖ FIXED | Added to `server.ts` + enforced in encryption service |
| **P0** | Multiple PrismaClient instances | ‚úÖ FIXED | Singleton in `lib/prisma.ts` |
| **P1** | No secret rotation strategy | ‚úÖ FIXED | JWT/webhook rotation scripts created |
| **P1** | Generic BullMQ retry policy | ‚úÖ FIXED | Job-specific policies + circuit breaker |
| **P2** | No soak testing | ‚úÖ FIXED | 4 comprehensive load tests created |
| **P2** | No encryption key versioning | ‚úÖ FIXED | Schema updated + migration created |
| **P1** | No connection pool monitoring | ‚úÖ FIXED | Pool metrics service + `/metrics` endpoint |
| **P1** | No DLQ monitoring | ‚úÖ FIXED | DLQ monitor service + Sentry alerts |
| **P2** | Hardcoded rate limits | ‚úÖ FIXED | All limits configurable via env vars |

### üìã Phase B Completion Checklist

- [ ] Fix missing env schema variables (P0)
- [ ] Implement PrismaClient singleton (P0)
- [ ] Create secret rotation scripts (P1)
- [ ] Configure Postgres connection pool tuning (P1)
- [ ] Implement job-specific BullMQ retry policies (P1)
- [ ] Add load test scenarios (USSD, SMS, admin) (P2)
- [ ] Document encryption key rotation procedure (P2)
- [ ] Set up monitoring for connection pools (P2)
- [ ] Create circuit breaker for external APIs (P2)

---

*Next: Implement P0/P1 fixes and re-run full test suite*
